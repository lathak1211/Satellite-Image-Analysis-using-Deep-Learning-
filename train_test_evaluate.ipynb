{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Classification: Train, Test, and Evaluate Model\n",
        "\n",
        "This notebook trains an image classification model on 4 classes (cloudy, desert, green_area, water), tests it, and evaluates its accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.17.0-dev20240417\n",
            "GPU Available: []\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Deep learning libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Preprocess Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class labels: {'cloudy': 0, 'desert': 1, 'green_area': 2, 'water': 3}\n"
          ]
        }
      ],
      "source": [
        "# Define parameters\n",
        "IMG_SIZE = (224, 224)  # Standard size for transfer learning\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# Define class folders\n",
        "class_folders = ['cloudy', 'desert', 'green_area', 'water']\n",
        "class_labels = {folder: idx for idx, folder in enumerate(class_folders)}\n",
        "print(\"Class labels:\", class_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading images...\n",
            "Loading cloudy...\n",
            "  Loaded 1500 images from cloudy\n",
            "Loading desert...\n",
            "  Loaded 1131 images from desert\n",
            "Loading green_area...\n",
            "Error loading .\\green_area\\Forest_1955.jpg: Unable to allocate 1.15 MiB for an array with shape (224, 224, 3) and data type float64\n",
            "Error loading .\\green_area\\Forest_1995.jpg: Unable to allocate 1.15 MiB for an array with shape (224, 224, 3) and data type float64\n",
            "Error loading .\\green_area\\Forest_2005.jpg: Unable to allocate 1.15 MiB for an array with shape (224, 224, 3) and data type float64\n",
            "Error loading .\\green_area\\Forest_2007.jpg: Unable to allocate 1.15 MiB for an array with shape (224, 224, 3) and data type float64\n",
            "Error loading .\\green_area\\Forest_2009.jpg: Unable to allocate 1.15 MiB for an array with shape (224, 224, 3) and data type float64\n",
            "Error loading .\\green_area\\Forest_2010.jpg: Unable to allocate 1.15 MiB for an array with shape (224, 224, 3) and data type float64\n",
            "Error loading .\\green_area\\Forest_2011.jpg: Unable to allocate 1.15 MiB for an array with shape (224, 224, 3) and data type float64\n",
            "Error loading .\\green_area\\Forest_2012.jpg: Unable to allocate 1.15 MiB for an array with shape (224, 224, 3) and data type float64\n"
          ]
        }
      ],
      "source": [
        "# Load images and labels with memory optimization\n",
        "def load_images_from_folder(folder_path, label, img_size=IMG_SIZE):\n",
        "    \"\"\"Load all images from a folder and assign labels - using float32 for memory efficiency\"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    folder_full_path = os.path.join('.', folder_path)\n",
        "    \n",
        "    if not os.path.exists(folder_full_path):\n",
        "        print(f\"Warning: Folder {folder_full_path} does not exist\")\n",
        "        return images, labels\n",
        "    \n",
        "    image_files = [f for f in os.listdir(folder_full_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    \n",
        "    for img_file in image_files:\n",
        "        try:\n",
        "            img_path = os.path.join(folder_full_path, img_file)\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            img = img.resize(img_size)\n",
        "            # Convert to float32 immediately to save memory (half the size of float64)\n",
        "            img_array = (np.array(img, dtype=np.float32) / 255.0).astype(np.float32)\n",
        "            images.append(img_array)\n",
        "            labels.append(label)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {img_path}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    return images, labels\n",
        "\n",
        "# Load all data\n",
        "all_images = []\n",
        "all_labels = []\n",
        "\n",
        "print(\"Loading images...\")\n",
        "for folder in class_folders:\n",
        "    print(f\"Loading {folder}...\")\n",
        "    images, labels = load_images_from_folder(folder, class_labels[folder])\n",
        "    all_images.extend(images)\n",
        "    all_labels.extend(labels)\n",
        "    print(f\"  Loaded {len(images)} images from {folder}\")\n",
        "\n",
        "# Convert to numpy arrays with explicit float32 dtype\n",
        "X = np.array(all_images, dtype=np.float32)\n",
        "y = np.array(all_labels, dtype=np.int32)\n",
        "\n",
        "print(f\"\\nTotal images loaded: {X.shape[0]}\")\n",
        "print(f\"Image shape: {X.shape[1:]}\")\n",
        "print(f\"Data type: {X.dtype} (memory efficient)\")\n",
        "print(f\"Number of classes: {len(class_folders)}\")\n",
        "print(f\"Class distribution: {np.bincount(y)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, \n",
        "    test_size=TEST_SIZE, \n",
        "    random_state=RANDOM_STATE, \n",
        "    stratify=y  # Ensure balanced split\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")\n",
        "print(f\"Training class distribution: {np.bincount(y_train)}\")\n",
        "print(f\"Test class distribution: {np.bincount(y_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Build Model (Transfer Learning with VGG16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build model using transfer learning\n",
        "def create_model(num_classes=4):\n",
        "    # Load pre-trained VGG16 model\n",
        "    base_model = VGG16(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
        "    )\n",
        "    \n",
        "    # Freeze base model layers\n",
        "    base_model.trainable = False\n",
        "    \n",
        "    # Add custom classification head\n",
        "    inputs = keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(num_classes=len(class_folders))\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Display model architecture\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create data augmentation generator for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# For validation/test, only rescale\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "# Create generators\n",
        "train_generator = train_datagen.flow(\n",
        "    X_train, y_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow(\n",
        "    X_test, y_test,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define callbacks\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=3,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=2,\n",
        "        min_lr=0.00001\n",
        "    )\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=len(X_test) // BATCH_SIZE,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nTraining completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualize Training History\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Plot accuracy\n",
        "axes[0].plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
        "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
        "axes[0].set_title('Model Accuracy')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True)\n",
        "\n",
        "# Plot loss\n",
        "axes[1].plot(history.history['loss'], label='Training Loss', marker='o')\n",
        "axes[1].plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
        "axes[1].set_title('Model Loss')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Loss')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Test and Evaluate the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on test set\n",
        "print(\"Making predictions on test set...\")\n",
        "y_pred_proba = model.predict(X_test, verbose=1)\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "print(f\"{'='*50}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(\"=\"*50)\n",
        "print(classification_report(\n",
        "    y_test, \n",
        "    y_pred, \n",
        "    target_names=class_folders,\n",
        "    digits=4\n",
        "))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    cm, \n",
        "    annot=True, \n",
        "    fmt='d', \n",
        "    cmap='Blues',\n",
        "    xticklabels=class_folders,\n",
        "    yticklabels=class_folders\n",
        ")\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate per-class accuracy\n",
        "print(\"\\nPer-Class Accuracy:\")\n",
        "print(\"=\"*50)\n",
        "for i, class_name in enumerate(class_folders):\n",
        "    class_mask = y_test == i\n",
        "    if np.sum(class_mask) > 0:\n",
        "        class_accuracy = accuracy_score(y_test[class_mask], y_pred[class_mask])\n",
        "        print(f\"{class_name:15s}: {class_accuracy:.4f} ({class_accuracy*100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualize Sample Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display sample predictions\n",
        "def plot_sample_predictions(X_test, y_test, y_pred, y_pred_proba, num_samples=12):\n",
        "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
        "    axes = axes.ravel()\n",
        "    \n",
        "    # Select random samples\n",
        "    indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
        "    \n",
        "    for idx, ax in enumerate(axes):\n",
        "        i = indices[idx]\n",
        "        ax.imshow(X_test[i])\n",
        "        true_label = class_folders[y_test[i]]\n",
        "        pred_label = class_folders[y_pred[i]]\n",
        "        confidence = y_pred_proba[i][y_pred[i]] * 100\n",
        "        \n",
        "        color = 'green' if y_test[i] == y_pred[i] else 'red'\n",
        "        ax.set_title(f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.1f}%', \n",
        "                    color=color, fontsize=10)\n",
        "        ax.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_sample_predictions(X_test, y_test, y_pred, y_pred_proba)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL MODEL EVALUATION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total Training Samples: {len(X_train)}\")\n",
        "print(f\"Total Test Samples: {len(X_test)}\")\n",
        "print(f\"Number of Classes: {len(class_folders)}\")\n",
        "print(f\"Classes: {', '.join(class_folders)}\")\n",
        "print(f\"\\nTest Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "print(f\"Final Training Accuracy: {history.history['accuracy'][-1]:.4f} ({history.history['accuracy'][-1]*100:.2f}%)\")\n",
        "print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]:.4f} ({history.history['val_accuracy'][-1]*100:.2f}%)\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
